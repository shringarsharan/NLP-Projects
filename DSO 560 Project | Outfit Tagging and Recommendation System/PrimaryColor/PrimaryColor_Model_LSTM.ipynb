{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PrimaryColor_Model_LSTM(1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OZMWoVO4kknG",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential \n",
        "from keras.layers import Input, Masking\n",
        "from keras.layers import Dense, Input, Reshape\n",
        "from keras.layers import Dropout, Activation\n",
        "from keras.layers import Dense, GlobalAveragePooling1D, Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM, SimpleRNN\n",
        "from keras.layers import Embedding\n",
        "import keras.backend as K \n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1J88vxQgkvZY",
        "outputId": "d0ceb7a7-95b1-4779-b85f-3ca4d8697028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "# read the data\n",
        "df = pd.read_excel('data.xlsx')\n",
        "\n",
        "# creating a subset of the relevant attribute name and then dropping the column\n",
        "df = df[df['attribute_name'] == 'primarycolor'].drop(columns = ['attribute_name'])\n",
        "\n",
        "# combining similar category attribute values and removing spaces\n",
        "# df['attribute_value'] = df['attribute_value'].apply(lambda x: 'semifit' if x == 'semi fit' else x)\n",
        "# df['attribute_value'] = df['attribute_value'].apply(lambda x: 'fittedtailor' if x == 'fitted tailor' else x)\n",
        "# df['attribute_value'] = df['attribute_value'].apply(lambda x: 'semifit' if x == 'semifitte' else x)\n",
        "# df['attribute_value'] = df['attribute_value'].apply(lambda x: 'fittedtailor' if x == 'fittedtailore' else x)\n",
        "# df['attribute_value'] = df['attribute_value'].apply(lambda x: 'straightregular' if x == 'straight regular' else x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.8 s, sys: 288 ms, total: 12.1 s\n",
            "Wall time: 14.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vyu18_culshy",
        "outputId": "740878ca-69c1-4f96-d6dd-a4e3cab464da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>brand</th>\n",
              "      <th>product_full_name</th>\n",
              "      <th>description</th>\n",
              "      <th>brand_category</th>\n",
              "      <th>attribute_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2852</th>\n",
              "      <td>01E603S8HDAQM7HKKYDYQQR9R9</td>\n",
              "      <td>simon miller</td>\n",
              "      <td>tone high waist wide leg jean</td>\n",
              "      <td>light wash cuff raw , fraying edge create cool...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2857</th>\n",
              "      <td>01E5ZWWZG54Q290WNC1D2D92EV</td>\n",
              "      <td>l c</td>\n",
              "      <td>cicely pintuck linen blend maxi dress</td>\n",
              "      <td>pintucked detail create flattering empire wais...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>pinks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2859</th>\n",
              "      <td>01DVA4YHJQNP81XPB75JBGQ749</td>\n",
              "      <td>jimmy choo</td>\n",
              "      <td>erin suede slingback point toe flat</td>\n",
              "      <td>slight heel navy suede goat buckle fastening s...</td>\n",
              "      <td>shoe flat shoe point toe flat</td>\n",
              "      <td>navy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>01DTJ8DQ5SQYBS5HX6TDH2BSJP</td>\n",
              "      <td>hunt season</td>\n",
              "      <td>leather panel raffia shoulder bag</td>\n",
              "      <td>handwoven local artisan , hunt season 's shoul...</td>\n",
              "      <td>woman bags shoulder bag</td>\n",
              "      <td>beige</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2866</th>\n",
              "      <td>01DTJ8DQ5SQYBS5HX6TDH2BSJP</td>\n",
              "      <td>hunt season</td>\n",
              "      <td>leather panel raffia shoulder bag</td>\n",
              "      <td>handwoven local artisan , hunt season 's shoul...</td>\n",
              "      <td>woman bags shoulder bag</td>\n",
              "      <td>darkbrown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      product_id         brand  \\\n",
              "2852  01E603S8HDAQM7HKKYDYQQR9R9  simon miller   \n",
              "2857  01E5ZWWZG54Q290WNC1D2D92EV           l c   \n",
              "2859  01DVA4YHJQNP81XPB75JBGQ749    jimmy choo   \n",
              "2861  01DTJ8DQ5SQYBS5HX6TDH2BSJP   hunt season   \n",
              "2866  01DTJ8DQ5SQYBS5HX6TDH2BSJP   hunt season   \n",
              "\n",
              "                          product_full_name  \\\n",
              "2852          tone high waist wide leg jean   \n",
              "2857  cicely pintuck linen blend maxi dress   \n",
              "2859    erin suede slingback point toe flat   \n",
              "2861      leather panel raffia shoulder bag   \n",
              "2866      leather panel raffia shoulder bag   \n",
              "\n",
              "                                            description  \\\n",
              "2852  light wash cuff raw , fraying edge create cool...   \n",
              "2857  pintucked detail create flattering empire wais...   \n",
              "2859  slight heel navy suede goat buckle fastening s...   \n",
              "2861  handwoven local artisan , hunt season 's shoul...   \n",
              "2866  handwoven local artisan , hunt season 's shoul...   \n",
              "\n",
              "                     brand_category attribute_value  \n",
              "2852                        unknown            blue  \n",
              "2857                        unknown           pinks  \n",
              "2859  shoe flat shoe point toe flat            navy  \n",
              "2861        woman bags shoulder bag           beige  \n",
              "2866        woman bags shoulder bag       darkbrown  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4KCfa3CVn9nY",
        "colab": {}
      },
      "source": [
        "# creating a feature combining brand, productname, description and brand category\n",
        "\n",
        "df['text'] = (df['brand'] + ' ' + df['product_full_name'] + ' ' + df['description'] + ' ' + df['brand_category']).apply(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WMi2ULgelhFo",
        "colab": {}
      },
      "source": [
        "# the predictor 'text' is assigned to 'X' and the 'attribute_value' t 'y'\n",
        "X = df['text'].values\n",
        "# one-hot-encoding the y variable\n",
        "y = pd.get_dummies(df['attribute_value']).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzVUuD0Mys-w",
        "colab_type": "text"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0YFmF01NwQGo",
        "colab": {}
      },
      "source": [
        "# creating a function to create uni-grams and tokenizing data\n",
        "def encode_1gram(X, mode = 'binary'):\n",
        "    tokenizer = Tokenizer(num_words=500)\n",
        "    tokenizer.fit_on_texts(X)\n",
        "    length = max([len(s.split()) for s in df['text']])\n",
        "    X = tokenizer.texts_to_matrix(X)\n",
        "    X = pad_sequences(X, maxlen=length, padding='post')\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    return X, length, vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5oETme721eAP",
        "colab": {}
      },
      "source": [
        "# creating a function to create bi-grams and tokenizing data\n",
        "def encode_2gram(X, mode='binary'):\n",
        "    phrases = Phrases(X, min_count=30)\n",
        "    bigrams = Phraser(phrases)\n",
        "    X = list(bigrams[X])\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=500)\n",
        "    tokenizer.fit_on_texts(X)\n",
        "    length = max([len(s.split()) for s in df['text']])\n",
        "    X = tokenizer.texts_to_matrix(X)\n",
        "    X = pad_sequences(X, maxlen=length, padding='post')\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    return X, length, vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "30eS_YrlwyL9",
        "outputId": "b84530f8-b367-4fd0-bd99-47df41a323de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x14806e0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6oEaE9mamM7X",
        "colab": {}
      },
      "source": [
        "# creating tf-idf vectors from uni-gram encoding\n",
        "X1, length1, vocab_size1 = encode_1gram(X, mode = 'tfidf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YGFzNuUUxWmZ",
        "colab": {}
      },
      "source": [
        "# creating tf-idf vectors from bi-gram encoding\n",
        "X2, length2, vocab_size2 = encode_2gram(X, mode = 'tfidf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hJpzT_ygA7Pw",
        "outputId": "a7c9e3dd-d50e-4985-f579-81fbcb576a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5306, 155)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yf8Gl0NGA1HV",
        "colab": {}
      },
      "source": [
        "# concatenating uni-gram and bi-gram\n",
        "X = np.concatenate([X1, X2], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ae88zjZ9CZye",
        "colab": {}
      },
      "source": [
        "# splitting data into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VDwRtJkSBvxp",
        "colab": {}
      },
      "source": [
        "# balancing the sample sets as the proportion of labels is unbalanced\n",
        "resampler = SMOTETomek(sampling_strategy = 'auto')\n",
        "X_train, y_train = resampler.fit_resample(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XNTeR6ZRoxcL",
        "colab": {}
      },
      "source": [
        "num_classes = y.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-xgZ_gpen5wR",
        "colab": {}
      },
      "source": [
        "# defining LSTM model with sigmoid activation functions for prediction\n",
        "def define_model_LSTM():\n",
        "    inputs = Input(shape=(length1+length2,))\n",
        "    embedding = Embedding(input_dim=vocab_size1, output_dim=100)(inputs)\n",
        "\n",
        "    x = LSTM(16, return_sequences=True, dropout=0.2, recurrent_dropout=0.15)(embedding)\n",
        "\n",
        "    x = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(x)\n",
        "    x = Conv1D(filters=num_classes, kernel_size=310, padding='valid')(x)\n",
        "    x = Reshape((num_classes,))(x)\n",
        "    out = Activation('softmax')(x)\n",
        "\n",
        "    model = Model(inputs = [inputs], outputs = out)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WtVkDeU4pOFw",
        "outputId": "fcfe73b5-6956-4e64-c55f-22bfad80a441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "model = define_model_LSTM()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 310)               0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 310, 100)          611900    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 310, 16)           7488      \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 310, 19)           323       \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 1, 19)             111929    \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 19)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 19)                0         \n",
            "=================================================================\n",
            "Total params: 731,640\n",
            "Trainable params: 731,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wfeN4H1XpRvM",
        "outputId": "d858c53d-ad4d-403e-94dc-e044d48f9dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "# fitting data onto model\n",
        "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/dhwanikapadia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20063 samples, validate on 5016 samples\n",
            "Epoch 1/10\n",
            "20063/20063 [==============================] - 25s 1ms/step - loss: 0.1990 - accuracy: 0.9474 - val_loss: 0.3313 - val_accuracy: 0.9474\n",
            "Epoch 2/10\n",
            "20063/20063 [==============================] - 24s 1ms/step - loss: 0.1976 - accuracy: 0.9474 - val_loss: 0.3589 - val_accuracy: 0.9474\n",
            "Epoch 3/10\n",
            "20063/20063 [==============================] - 25s 1ms/step - loss: 0.1948 - accuracy: 0.9474 - val_loss: 0.3735 - val_accuracy: 0.9474\n",
            "Epoch 4/10\n",
            "20063/20063 [==============================] - 23s 1ms/step - loss: 0.1882 - accuracy: 0.9479 - val_loss: 0.3692 - val_accuracy: 0.9472\n",
            "Epoch 5/10\n",
            "20063/20063 [==============================] - 20s 984us/step - loss: 0.1840 - accuracy: 0.9485 - val_loss: 0.3551 - val_accuracy: 0.9471\n",
            "Epoch 6/10\n",
            "20063/20063 [==============================] - 19s 947us/step - loss: 0.1816 - accuracy: 0.9487 - val_loss: 0.3602 - val_accuracy: 0.9472\n",
            "Epoch 7/10\n",
            "20063/20063 [==============================] - 17s 871us/step - loss: 0.1805 - accuracy: 0.9488 - val_loss: 0.3442 - val_accuracy: 0.9470\n",
            "Epoch 8/10\n",
            "20063/20063 [==============================] - 18s 908us/step - loss: 0.1799 - accuracy: 0.9487 - val_loss: 0.3525 - val_accuracy: 0.9468\n",
            "Epoch 9/10\n",
            "20063/20063 [==============================] - 18s 884us/step - loss: 0.1796 - accuracy: 0.9487 - val_loss: 0.3786 - val_accuracy: 0.9468\n",
            "Epoch 10/10\n",
            "20063/20063 [==============================] - 18s 884us/step - loss: 0.1792 - accuracy: 0.9487 - val_loss: 0.3770 - val_accuracy: 0.9470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x159d9feb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RH0rgY1WChE4",
        "outputId": "fd677c2f-c95c-4c7e-bed6-3e6222c2a153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# evaluating model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "531/531 [==============================] - 0s 683us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21767208448798867, 0.9426107406616211]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ythmDKKlpjsc",
        "outputId": "d6f16597-3d88-4156-9dfd-18e674c16b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "#predictions for each class from predicting model\n",
        "pd.Series(model.predict(X).argmax(axis = -1)).value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5     1817\n",
              "1      678\n",
              "4      412\n",
              "2      391\n",
              "12     257\n",
              "17     252\n",
              "6      241\n",
              "8      240\n",
              "10     203\n",
              "0      153\n",
              "13     143\n",
              "7      137\n",
              "11     137\n",
              "9      135\n",
              "14      73\n",
              "3       29\n",
              "16       4\n",
              "18       4\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xjn1GCho_snJ",
        "outputId": "64e89209-019a-46ea-b9e1-0ddd7a3ce7aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# probability of predicting each class for various records\n",
        "model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.09992214e-01, 4.35838699e-02, 6.12151325e-02, ...,\n",
              "        1.06188265e-04, 3.86776514e-02, 4.35510743e-03],\n",
              "       [1.64481101e-03, 7.71445036e-02, 4.29336399e-01, ...,\n",
              "        4.60881332e-04, 1.18156224e-01, 8.77555180e-03],\n",
              "       [7.52144083e-02, 3.22915837e-02, 5.50202467e-02, ...,\n",
              "        2.24964431e-04, 2.13452484e-02, 1.99981523e-03],\n",
              "       ...,\n",
              "       [6.59008101e-02, 1.10627957e-01, 7.70954266e-02, ...,\n",
              "        1.86874787e-03, 1.08826131e-01, 2.35029636e-03],\n",
              "       [7.52144009e-02, 3.22915800e-02, 5.50202429e-02, ...,\n",
              "        2.24964417e-04, 2.13452447e-02, 1.99981499e-03],\n",
              "       [1.34782949e-02, 1.41287267e-01, 2.91009005e-02, ...,\n",
              "        3.02958046e-03, 7.33574778e-02, 5.17956913e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5WsQqrmxprsc",
        "outputId": "ae856a95-e7c3-4788-e1e7-d646f27a7852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# split of classes\n",
        "pd.Series(y.argmax(axis = -1)).value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     1449\n",
              "17     908\n",
              "2      511\n",
              "12     288\n",
              "6      268\n",
              "7      260\n",
              "0      249\n",
              "8      244\n",
              "4      241\n",
              "10     223\n",
              "14     176\n",
              "18      96\n",
              "11      77\n",
              "9       73\n",
              "5       73\n",
              "13      61\n",
              "3       56\n",
              "15      44\n",
              "16       9\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BmfNQQbrqhhc",
        "colab": {}
      },
      "source": [
        "### LSTM Glove"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jWyJpsHytDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df['text'].values\n",
        "y = pd.get_dummies(df['attribute_value'])\n",
        "label_list = y.columns\n",
        "y = y.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mejwt1zUytDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizing the data and integer encoding it\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
        "tokenizer.fit_on_texts(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcGTpsOLytDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# running the tokenizer function on features\n",
        "\n",
        "X = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q-spQpOytDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting vocab size and length for input\n",
        "\n",
        "length = max([len(s.split()) for s in df['text']])\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8svwv6udytDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padding the data to make it same size (max size)\n",
        "\n",
        "X = pad_sequences(X, maxlen=length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPcD3zFCytD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# splitting training and testing data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cml4CsD2ytEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# balancing the dataset to account for disproportionate of labels\n",
        "\n",
        "resampler = SMOTETomek(sampling_strategy = 'auto')\n",
        "X_train, y_train = resampler.fit_resample(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxBiwsMbytER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = y.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaZ3hYaeytEd",
        "colab_type": "code",
        "colab": {},
        "outputId": "ca723e8a-b1cc-4eff-d1c2-e29dc9adfef8"
      },
      "source": [
        "# using glove vector to create function that makes word emebeddings\n",
        "\n",
        "def load_glove_vectors():\n",
        "    embeddings_index = {}\n",
        "    with open('glove.6B.100d.txt') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "    return embeddings_index\n",
        "\n",
        "\n",
        "embeddings_index = load_glove_vectors()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHb0chv1ytEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8lNrdtSytEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating an LSTM Glove model\n",
        "\n",
        "def define_model_LSTM_Glove():\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=length, trainable=False))\n",
        "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
        "    model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.15, activation = 'relu'))\n",
        "    model.add(LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.15, activation = 'relu'))\n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oIdBPvLytE_",
        "colab_type": "code",
        "colab": {},
        "outputId": "435cc542-b4e0-42a9-c8a5-a0cd2acf38bf"
      },
      "source": [
        "model = define_model_LSTM_Glove()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 155, 100)          612000    \n",
            "_________________________________________________________________\n",
            "masking_2 (Masking)          (None, 155, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 155, 64)           42240     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 19)                323       \n",
            "=================================================================\n",
            "Total params: 688,627\n",
            "Trainable params: 76,627\n",
            "Non-trainable params: 612,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlk3pwADytFO",
        "colab_type": "code",
        "colab": {},
        "outputId": "f33d2af2-fe59-4a61-c456-12fe6402ebd0"
      },
      "source": [
        "# fitting model on training data\n",
        "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 19727 samples, validate on 4932 samples\n",
            "Epoch 1/10\n",
            "19727/19727 [==============================] - 45s 2ms/step - loss: 0.2047 - accuracy: 0.9474 - val_loss: 0.2307 - val_accuracy: 0.9474\n",
            "Epoch 2/10\n",
            "19727/19727 [==============================] - 43s 2ms/step - loss: 0.2017 - accuracy: 0.9474 - val_loss: 0.2617 - val_accuracy: 0.9474\n",
            "Epoch 3/10\n",
            "19727/19727 [==============================] - 43s 2ms/step - loss: 0.1979 - accuracy: 0.9474 - val_loss: 0.3020 - val_accuracy: 0.9474\n",
            "Epoch 4/10\n",
            "19727/19727 [==============================] - 43s 2ms/step - loss: 0.1950 - accuracy: 0.9474 - val_loss: 0.3463 - val_accuracy: 0.9474\n",
            "Epoch 5/10\n",
            "19727/19727 [==============================] - 43s 2ms/step - loss: 0.1932 - accuracy: 0.9473 - val_loss: 0.3596 - val_accuracy: 0.9474\n",
            "Epoch 6/10\n",
            "19727/19727 [==============================] - 43s 2ms/step - loss: 0.1918 - accuracy: 0.9474 - val_loss: 0.3840 - val_accuracy: 0.9474\n",
            "Epoch 7/10\n",
            "19727/19727 [==============================] - 43s 2ms/step - loss: 0.1908 - accuracy: 0.9474 - val_loss: 0.4017 - val_accuracy: 0.9474\n",
            "Epoch 8/10\n",
            "19727/19727 [==============================] - 43s 2ms/step - loss: 0.1899 - accuracy: 0.9474 - val_loss: 0.4104 - val_accuracy: 0.9474\n",
            "Epoch 9/10\n",
            "19727/19727 [==============================] - 44s 2ms/step - loss: 0.1888 - accuracy: 0.9474 - val_loss: 0.3927 - val_accuracy: 0.9474\n",
            "Epoch 10/10\n",
            "19727/19727 [==============================] - 44s 2ms/step - loss: 0.1884 - accuracy: 0.9474 - val_loss: 0.4254 - val_accuracy: 0.9474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x148c8fe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-NMt69VytFZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "79751c27-2fe5-488a-f286-29d86950d876"
      },
      "source": [
        "# evaluating model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "531/531 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18758753941108502, 0.9479632377624512]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G5qIqhSytFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making predictions\n",
        "results = model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGqDcymuytF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining a threshold for prediction\n",
        "results_df = pd.DataFrame()\n",
        "results_mask = results > 0.1\n",
        "for i in range(len(label_list)):\n",
        "    results_df[label_list[i]] = results_mask[:,i]\n",
        "    results_df[label_list[i]] = results_df[label_list[i]].apply(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSIMRT54ytGB",
        "colab_type": "code",
        "colab": {},
        "outputId": "2881fe02-2302-49c7-b857-b7ce9609e6cd"
      },
      "source": [
        "results_df['sum']  = 0\n",
        "for key in label_list:\n",
        "    results_df['sum'] = results_df['sum'] + results_df[key]\n",
        "(results_df['sum'] == 0).sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcVOzpHGytGH",
        "colab_type": "code",
        "colab": {},
        "outputId": "54f7f9c1-b39a-490b-825e-00d5969edd02"
      },
      "source": [
        "results_df = results_df.drop(columns = ['sum'])\n",
        "for key in label_list:\n",
        "    results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
        "\n",
        "results_df['attribute_value'] = ''\n",
        "for key in label_list:\n",
        "    results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
        "\n",
        "results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
        "results_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>beige</th>\n",
              "      <th>black</th>\n",
              "      <th>blue</th>\n",
              "      <th>burgundy</th>\n",
              "      <th>darkbrown</th>\n",
              "      <th>gold</th>\n",
              "      <th>gray</th>\n",
              "      <th>greens</th>\n",
              "      <th>lightbrowns</th>\n",
              "      <th>multi</th>\n",
              "      <th>navy</th>\n",
              "      <th>orange</th>\n",
              "      <th>pinks</th>\n",
              "      <th>purple</th>\n",
              "      <th>red</th>\n",
              "      <th>silver</th>\n",
              "      <th>teal</th>\n",
              "      <th>white</th>\n",
              "      <th>yellow</th>\n",
              "      <th>attribute_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>black</td>\n",
              "      <td>blue</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>white</td>\n",
              "      <td></td>\n",
              "      <td>black, blue, white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>black</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>white</td>\n",
              "      <td></td>\n",
              "      <td>black, white</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>black</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>black</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>black</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  beige  black  blue burgundy darkbrown gold gray greens lightbrowns multi  \\\n",
              "0        black  blue                                                         \n",
              "1        black                                                               \n",
              "2                                                                            \n",
              "3        black                                                               \n",
              "4        black                                                               \n",
              "\n",
              "  navy orange pinks purple red silver teal  white yellow     attribute_value  \n",
              "0                                           white         black, blue, white  \n",
              "1                                           white               black, white  \n",
              "2                                                                             \n",
              "3                                                                      black  \n",
              "4                                                                      black  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Pll5GIytGT",
        "colab_type": "code",
        "colab": {},
        "outputId": "724a73a8-84cf-46c7-d77e-8324f4f6c60c"
      },
      "source": [
        "results_df['attribute_value'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "black, white                   2064\n",
              "                               1194\n",
              "black                           993\n",
              "black, blue, white              395\n",
              "multi, orange                   342\n",
              "multi                            80\n",
              "black, multi                     52\n",
              "black, blue                      45\n",
              "blue, white                      27\n",
              "blue                             26\n",
              "gold                             19\n",
              "black, multi, white              17\n",
              "gold, gray, lightbrowns           7\n",
              "gray                              7\n",
              "lightbrowns                       6\n",
              "orange                            5\n",
              "pinks                             4\n",
              "burgundy, gold                    4\n",
              "navy                              3\n",
              "burgundy                          3\n",
              "multi, navy                       2\n",
              "black, darkbrown                  2\n",
              "burgundy, gold, lightbrowns       2\n",
              "blue, navy                        2\n",
              "blue, multi, orange               1\n",
              "gold, gray                        1\n",
              "black, blue, gray                 1\n",
              "black, navy                       1\n",
              "burgundy, lightbrowns             1\n",
              "Name: attribute_value, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgAQEtRHytGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import spacy\n",
        "import pickle\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('model.pickle', 'wb') as handle:\n",
        "    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQYoTBH-ytG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_primarycolor(brand, product_full_name, description, details, brand_category):\n",
        "    def clean_text(x):\n",
        "        try:\n",
        "            x = re.sub(r'<.*?>', '',x)\n",
        "            x = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", x)\n",
        "            x = re.sub(r\"\\'s\", \" \\'s\", x)\n",
        "            x = re.sub(r\"\\'ve\", \" \\'ve\", x)\n",
        "            x = re.sub(r\"n\\'t\", \" n\\'t\", x)\n",
        "            x = re.sub(r\"\\'re\", \" \\'re\", x)\n",
        "            x = re.sub(r\"\\'d\", \" \\'d\", x)\n",
        "            x = re.sub(r\"\\'ll\", \" \\'ll\", x)\n",
        "            x = re.sub(r\",\", \" , \", x)\n",
        "            x = re.sub(r\"!\", \" ! \", x)\n",
        "            x = re.sub(r\"\\(\", \"\", x)\n",
        "            x = re.sub(r\"\\)\", \"\", x)\n",
        "            x = re.sub(r\"\\?\", \"\", x)\n",
        "            x = re.sub(r\"/\", \"\", x)\n",
        "            x = re.sub(r\"\\s{2,}\", \" \", x)\n",
        "            return x.lower()\n",
        "        except:\n",
        "            return ''\n",
        "\n",
        "    def lemmatizer(x):\n",
        "        return ' '.join([token.lemma_ for token in nlp(x)])\n",
        "        \n",
        "    with open('tokenizer.pickle', 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle)\n",
        "    with open('model.pickle', 'rb') as handle:\n",
        "        model = pickle.load(handle)\n",
        "\n",
        "    data = pd.DataFrame({'brand':brand,'product_full_name':product_full_name,'description':description,'details':details,'brand_category':brand_category},index=[0]) \n",
        "    df = data.copy()\n",
        "    for key in df.columns:\n",
        "        df[key] = df[key].apply(clean_text)\n",
        "        df[key] = df[key].apply(remove_stopwords)\n",
        "        df[key] = df[key].apply(lemmatizer)\n",
        "        df[key] = df[key].apply(clean_text)\n",
        "        df[key] = df[key].apply(remove_stopwords)\n",
        "    df['text'] = (df['brand'] + ' ' + df['product_full_name'] + ' ' + df['description'] + ' ' + df['brand_category'] + ' ' + df['details']).apply(str)\n",
        "    X = df['text'].values\n",
        "    X = tokenizer.texts_to_sequences(X)\n",
        "    X = pad_sequences(X, maxlen=length, padding='post')\n",
        "    results = model.predict(X)\n",
        "    results_df = pd.DataFrame()\n",
        "    results_mask = results > 0.1\n",
        "    for i in range(len(label_list)):\n",
        "        results_df[label_list[i]] = results_mask[:,i]\n",
        "        results_df[label_list[i]] = results_df[label_list[i]].apply(int)\n",
        "    results_df['sum']  = 0\n",
        "    for key in label_list:\n",
        "        results_df['sum'] = results_df['sum'] + results_df[key]\n",
        "    (results_df['sum'] == 0).sum()\n",
        "    results_df = results_df.drop(columns = ['sum'])\n",
        "    for key in label_list:\n",
        "        results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
        "\n",
        "    results_df['attribute_value'] = ''\n",
        "    for key in label_list:\n",
        "        results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
        "\n",
        "    results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
        "    data['attribute_value'] = results_df['attribute_value']\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfqSwapUytG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brand = \"frame\"\n",
        "product_full_name = \"les second medium noir\"\n",
        "description = \"'minimal , modern styling meet refined luxury les second caba tote craft exquisite leather , structured handbag equip adjustable high polish peg buttonhole double drop handle , center welt seam , detachable pouch , frame logo discreetly emboss'\"\n",
        "details = np.nan\n",
        "brand_category = 'accessory'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugo_iCkfytHJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "1a4335ed-0ffe-43fb-951a-1963714e775f"
      },
      "source": [
        "get_primarycolor(brand, product_full_name, description, details, brand_category)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>product_full_name</th>\n",
              "      <th>description</th>\n",
              "      <th>details</th>\n",
              "      <th>brand_category</th>\n",
              "      <th>attribute_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame</td>\n",
              "      <td>les second medium noir</td>\n",
              "      <td>'minimal , modern styling meet refined luxury ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accessory</td>\n",
              "      <td>multi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   brand       product_full_name  \\\n",
              "0  frame  les second medium noir   \n",
              "\n",
              "                                         description  details brand_category  \\\n",
              "0  'minimal , modern styling meet refined luxury ...      NaN      accessory   \n",
              "\n",
              "  attribute_value  \n",
              "0           multi  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4A7UuI4ytHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results=pd.DataFrame(results)\n",
        "results.to_excel('results_pc.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX6JlQraytHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_df.to_excel('results_df_pc.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}