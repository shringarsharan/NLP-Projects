{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of Model_V5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OZMWoVO4kknG",
        "outputId": "9204e46e-ec70-4efa-fae9-66f6cfd8ad7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential \n",
        "from keras.layers import Input, Masking\n",
        "from keras.layers import Dense, Input, Reshape\n",
        "from keras.layers import Dropout, Activation\n",
        "from keras.layers import Dense, GlobalAveragePooling1D, Activation\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM, SimpleRNN\n",
        "from keras.layers import Embedding\n",
        "import keras.backend as K \n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models.phrases import Phraser, Phrases"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1J88vxQgkvZY",
        "outputId": "9392f3e6-bec1-4a29-8d7e-166e5334b8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "df = pd.read_excel('data.xlsx')\n",
        "df = df[df['attribute_name'] == 'style'].drop(columns = ['attribute_name'])\n",
        "\n",
        "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'semifit' if x == 'semi fit' else x)\n",
        "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'fittedtailor' if x == 'fitted tailor' else x)\n",
        "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'semifit' if x == 'semifitte' else x)\n",
        "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'fittedtailor' if x == 'fittedtailore' else x)\n",
        "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'straightregular' if x == 'straight regular' else x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.94 s, sys: 66.9 ms, total: 8.01 s\n",
            "Wall time: 8.03 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vyu18_culshy",
        "outputId": "3dd006d4-659d-493b-fb59-6e3737d06550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>brand</th>\n",
              "      <th>product_full_name</th>\n",
              "      <th>description</th>\n",
              "      <th>brand_category</th>\n",
              "      <th>attribute_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01DPGV4YRP3Z8J85DASGZ1Y99W</td>\n",
              "      <td>frame</td>\n",
              "      <td>les second medium noir</td>\n",
              "      <td>minimal , modern styling meet refined luxury l...</td>\n",
              "      <td>accessory</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>01DPH1DEN9G2WM7WAMJMD0A9W4</td>\n",
              "      <td>j crew</td>\n",
              "      <td>tie waist shirtdress stripe</td>\n",
              "      <td>take classic button silhouette turn ultra flat...</td>\n",
              "      <td>dressesandjumpsuits</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>01E2KYW52BAG606GQ7A9H5R0KD</td>\n",
              "      <td>alo</td>\n",
              "      <td>interval microfleece pullover hoodie</td>\n",
              "      <td>articulate seam extra wide rib hem create shap...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>01DT513RRYT3SKH6X25G5VCH6B</td>\n",
              "      <td>chlo</td>\n",
              "      <td>leather ankle boot</td>\n",
              "      <td>heel measure approximately 55 mm 2 inch 30 mm ...</td>\n",
              "      <td>shoe boots ankle</td>\n",
              "      <td>androgynous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>01E2KM0KW6NB1JKMZVRXR6H8G2</td>\n",
              "      <td>alo</td>\n",
              "      <td>stadium quarter zip hoodie</td>\n",
              "      <td>supersoft hoodie design elastic hem cuff perfe...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>casual</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    product_id   brand                     product_full_name  \\\n",
              "0   01DPGV4YRP3Z8J85DASGZ1Y99W   frame                les second medium noir   \n",
              "5   01DPH1DEN9G2WM7WAMJMD0A9W4  j crew           tie waist shirtdress stripe   \n",
              "12  01E2KYW52BAG606GQ7A9H5R0KD     alo  interval microfleece pullover hoodie   \n",
              "13  01DT513RRYT3SKH6X25G5VCH6B    chlo                    leather ankle boot   \n",
              "20  01E2KM0KW6NB1JKMZVRXR6H8G2     alo            stadium quarter zip hoodie   \n",
              "\n",
              "                                          description       brand_category  \\\n",
              "0   minimal , modern styling meet refined luxury l...            accessory   \n",
              "5   take classic button silhouette turn ultra flat...  dressesandjumpsuits   \n",
              "12  articulate seam extra wide rib hem create shap...              unknown   \n",
              "13  heel measure approximately 55 mm 2 inch 30 mm ...     shoe boots ankle   \n",
              "20  supersoft hoodie design elastic hem cuff perfe...              unknown   \n",
              "\n",
              "   attribute_value  \n",
              "0           casual  \n",
              "5           casual  \n",
              "12          casual  \n",
              "13     androgynous  \n",
              "20          casual  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4KCfa3CVn9nY",
        "colab": {}
      },
      "source": [
        "df['text'] = (df['brand'] + ' ' + df['product_full_name'] + ' ' + df['description'] + ' ' + df['brand_category']).apply(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WMi2ULgelhFo",
        "colab": {}
      },
      "source": [
        "X = df['text'].values\n",
        "y = pd.get_dummies(df['attribute_value'])\n",
        "label_list = y.columns\n",
        "y = y.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0YFmF01NwQGo",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
        "tokenizer.fit_on_texts(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5oETme721eAP",
        "colab": {}
      },
      "source": [
        "X = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_IMFmGLi6sUH",
        "colab": {}
      },
      "source": [
        "length = max([len(s.split()) for s in df['text']])\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jHn0BxkM6zbH",
        "colab": {}
      },
      "source": [
        "X = pad_sequences(X, maxlen=length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ae88zjZ9CZye",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VDwRtJkSBvxp",
        "colab": {}
      },
      "source": [
        "resampler = SMOTETomek(sampling_strategy = 'auto')\n",
        "X_train, y_train = resampler.fit_resample(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XNTeR6ZRoxcL",
        "colab": {}
      },
      "source": [
        "num_classes = y.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8F-6edne7CKl",
        "outputId": "097bb2be-7209-4b6c-c68b-c37825454cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def load_glove_vectors():\n",
        "    embeddings_index = {}\n",
        "    with open('glove.6B.100d.txt') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "    return embeddings_index\n",
        "\n",
        "\n",
        "embeddings_index = load_glove_vectors()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cm2saCqq7B6t",
        "colab": {}
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GEI2XRLs77Ws",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GcWVkLPD7Bq6",
        "colab": {}
      },
      "source": [
        "def define_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=length, trainable=False))\n",
        "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
        "    model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.15, activation = 'relu'))\n",
        "    model.add(LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.15, activation = 'relu'))\n",
        "    #model.add(Flatten())\n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "    model.add(Dense(num_classes, activation='sigmoid'))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RwR86N_D8RPY"
      },
      "source": [
        "def define_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=length, trainable=False))\n",
        "    #model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
        "    LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.15, activation = 'relu')\n",
        "    LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.15, activation = 'relu')\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "    model.add(Dense(num_classes, activation='sigmoid'))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WtVkDeU4pOFw",
        "outputId": "460ed4ea-4055-43ce-d5f0-842305ff6d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "model = define_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 155, 100)          611400    \n",
            "_________________________________________________________________\n",
            "masking_1 (Masking)          (None, 155, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 155, 64)           42240     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 687,908\n",
            "Trainable params: 76,508\n",
            "Non-trainable params: 611,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wfeN4H1XpRvM",
        "outputId": "a7fd9b7b-515e-4c34-9624-1ee11ba0ee32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 21980 samples, validate on 5496 samples\n",
            "Epoch 1/10\n",
            "21980/21980 [==============================] - 49s 2ms/step - loss: 0.6280 - accuracy: 0.7963 - val_loss: 0.5437 - val_accuracy: 0.8409\n",
            "Epoch 2/10\n",
            "21980/21980 [==============================] - 50s 2ms/step - loss: 0.4775 - accuracy: 0.8650 - val_loss: 0.4806 - val_accuracy: 0.8589\n",
            "Epoch 3/10\n",
            "21980/21980 [==============================] - 66s 3ms/step - loss: 0.4131 - accuracy: 0.9020 - val_loss: 0.4330 - val_accuracy: 0.9167\n",
            "Epoch 4/10\n",
            "21980/21980 [==============================] - 58s 3ms/step - loss: 0.3702 - accuracy: 0.9166 - val_loss: 0.4052 - val_accuracy: 0.9167\n",
            "Epoch 5/10\n",
            "21980/21980 [==============================] - 49s 2ms/step - loss: 0.3415 - accuracy: 0.9167 - val_loss: 0.3900 - val_accuracy: 0.9167\n",
            "Epoch 6/10\n",
            "21980/21980 [==============================] - 54s 2ms/step - loss: 0.3416 - accuracy: 0.9167 - val_loss: 0.4042 - val_accuracy: 0.9167\n",
            "Epoch 7/10\n",
            "21980/21980 [==============================] - 51s 2ms/step - loss: 0.3220 - accuracy: 0.9167 - val_loss: 0.4045 - val_accuracy: 0.9167\n",
            "Epoch 8/10\n",
            "21980/21980 [==============================] - 52s 2ms/step - loss: 0.3127 - accuracy: 0.9167 - val_loss: 0.3974 - val_accuracy: 0.9167\n",
            "Epoch 9/10\n",
            "21980/21980 [==============================] - 50s 2ms/step - loss: 0.3033 - accuracy: 0.9167 - val_loss: 0.4014 - val_accuracy: 0.9167\n",
            "Epoch 10/10\n",
            "21980/21980 [==============================] - 53s 2ms/step - loss: 0.2992 - accuracy: 0.9167 - val_loss: 0.4057 - val_accuracy: 0.9167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x14c97ae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RH0rgY1WChE4",
        "outputId": "f4ce2e73-b23f-41cc-b6e6-56e803fdebb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1089/1089 [==============================] - 1s 908us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3072939977884512, 0.9166664481163025]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ythmDKKlpjsc",
        "colab": {}
      },
      "source": [
        "results = model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xjn1GCho_snJ",
        "colab": {}
      },
      "source": [
        "results_df = pd.DataFrame()\n",
        "results_mask = results > 0.1\n",
        "for i in range(len(label_list)):\n",
        "    results_df[label_list[i]] = results_mask[:,i]\n",
        "    results_df[label_list[i]] = results_df[label_list[i]].apply(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5WsQqrmxprsc",
        "outputId": "950f9112-04c9-4c5b-bbfe-f5f1b9e6c1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "results_df['sum']  = 0\n",
        "for key in label_list:\n",
        "    results_df['sum'] = results_df['sum'] + results_df[key]\n",
        "(results_df['sum'] == 0).sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BmfNQQbrqhhc",
        "outputId": "66d36a59-9800-401a-c6ec-453e6cec4e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "results_df = results_df.drop(columns = ['sum'])\n",
        "for key in label_list:\n",
        "    results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
        "\n",
        "results_df['attribute_value'] = ''\n",
        "for key in label_list:\n",
        "    results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
        "\n",
        "results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
        "results_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>androgynous</th>\n",
              "      <th>athleisure</th>\n",
              "      <th>boho</th>\n",
              "      <th>business casual</th>\n",
              "      <th>businesscasual</th>\n",
              "      <th>casual</th>\n",
              "      <th>classic</th>\n",
              "      <th>edgy</th>\n",
              "      <th>glam</th>\n",
              "      <th>modern</th>\n",
              "      <th>retro</th>\n",
              "      <th>romantic</th>\n",
              "      <th>attribute_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>androgynous</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>boho</td>\n",
              "      <td>business casual</td>\n",
              "      <td>businesscasual</td>\n",
              "      <td>casual</td>\n",
              "      <td>classic</td>\n",
              "      <td>edgy</td>\n",
              "      <td>glam</td>\n",
              "      <td>modern</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>androgynous, athleisure, boho, business, casua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>androgynous</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>boho</td>\n",
              "      <td>business casual</td>\n",
              "      <td>businesscasual</td>\n",
              "      <td>casual</td>\n",
              "      <td>classic</td>\n",
              "      <td>edgy</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>androgynous, athleisure, boho, business, casua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>androgynous</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>boho</td>\n",
              "      <td>business casual</td>\n",
              "      <td>businesscasual</td>\n",
              "      <td>casual</td>\n",
              "      <td>classic</td>\n",
              "      <td>edgy</td>\n",
              "      <td></td>\n",
              "      <td>modern</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>androgynous, athleisure, boho, business, casua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>androgynous</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>boho</td>\n",
              "      <td>business casual</td>\n",
              "      <td>businesscasual</td>\n",
              "      <td>casual</td>\n",
              "      <td>classic</td>\n",
              "      <td>edgy</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>androgynous, athleisure, boho, business, casua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>androgynous</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>boho</td>\n",
              "      <td>business casual</td>\n",
              "      <td>businesscasual</td>\n",
              "      <td>casual</td>\n",
              "      <td>classic</td>\n",
              "      <td>edgy</td>\n",
              "      <td></td>\n",
              "      <td>modern</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>androgynous, athleisure, boho, business, casua...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   androgynous  athleisure  boho  business casual  businesscasual  casual  \\\n",
              "0  androgynous  athleisure  boho  business casual  businesscasual  casual   \n",
              "1  androgynous  athleisure  boho  business casual  businesscasual  casual   \n",
              "2  androgynous  athleisure  boho  business casual  businesscasual  casual   \n",
              "3  androgynous  athleisure  boho  business casual  businesscasual  casual   \n",
              "4  androgynous  athleisure  boho  business casual  businesscasual  casual   \n",
              "\n",
              "   classic  edgy  glam  modern retro romantic  \\\n",
              "0  classic  edgy  glam  modern                  \n",
              "1  classic  edgy                                \n",
              "2  classic  edgy        modern                  \n",
              "3  classic  edgy                                \n",
              "4  classic  edgy        modern                  \n",
              "\n",
              "                                     attribute_value  \n",
              "0  androgynous, athleisure, boho, business, casua...  \n",
              "1  androgynous, athleisure, boho, business, casua...  \n",
              "2  androgynous, athleisure, boho, business, casua...  \n",
              "3  androgynous, athleisure, boho, business, casua...  \n",
              "4  androgynous, athleisure, boho, business, casua...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBsLjXEzyvys",
        "outputId": "444ad9da-7118-432d-e42e-18fff98e3b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "results_df['attribute_value'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "androgynous, athleisure, boho, business, casual, businesscasual, casual, classic, edgy                                   4876\n",
              "androgynous, athleisure, boho, business, casual, businesscasual, casual, classic, edgy, modern                           1972\n",
              "androgynous, athleisure, boho, business, casual, businesscasual, casual, classic, edgy, glam, modern, retro, romantic    1384\n",
              "androgynous, athleisure, boho, business, casual, businesscasual, casual, classic, edgy, glam, modern                     1307\n",
              "androgynous, athleisure, boho, business, casual, casual, classic, edgy                                                    408\n",
              "athleisure, classic                                                                                                       223\n",
              "athleisure, boho, business, casual, casual, classic, edgy                                                                 138\n",
              "athleisure, boho, business, casual, classic                                                                               119\n",
              "classic                                                                                                                    99\n",
              "androgynous, athleisure, boho, business, casual, businesscasual, casual, classic                                           79\n",
              "athleisure, boho, business, casual, casual, classic                                                                        63\n",
              "athleisure, business, casual, classic                                                                                      42\n",
              "athleisure, boho, classic                                                                                                  31\n",
              "athleisure, business, casual, classic, edgy                                                                                28\n",
              "androgynous, athleisure, boho, business, casual, casual, classic                                                           25\n",
              "athleisure, classic, edgy                                                                                                  24\n",
              "athleisure, boho, business, casual, businesscasual, casual, classic                                                        20\n",
              "athleisure, boho, business, casual, classic, edgy                                                                          13\n",
              "athleisure, boho, business, casual, businesscasual, classic                                                                11\n",
              "athleisure, boho, casual, classic                                                                                           8\n",
              "athleisure, business, casual, casual, classic, edgy                                                                         8\n",
              "athleisure, businesscasual, classic                                                                                         3\n",
              "androgynous, athleisure, boho, casual, classic, edgy                                                                        2\n",
              "athleisure, boho, casual, classic, edgy                                                                                     2\n",
              "androgynous, athleisure, boho, business, casual, businesscasual, casual, classic, edgy, glam, modern, romantic              2\n",
              "Name: attribute_value, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU5g6AqmjOj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import spacy\n",
        "import pickle\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('model.pickle', 'wb') as handle:\n",
        "    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BMG468TjOkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fit(brand, product_full_name, description, details, brand_category):\n",
        "    def clean_text(x):\n",
        "        try:\n",
        "            x = re.sub(r'<.*?>', '',x)\n",
        "            x = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", x)\n",
        "            x = re.sub(r\"\\'s\", \" \\'s\", x)\n",
        "            x = re.sub(r\"\\'ve\", \" \\'ve\", x)\n",
        "            x = re.sub(r\"n\\'t\", \" n\\'t\", x)\n",
        "            x = re.sub(r\"\\'re\", \" \\'re\", x)\n",
        "            x = re.sub(r\"\\'d\", \" \\'d\", x)\n",
        "            x = re.sub(r\"\\'ll\", \" \\'ll\", x)\n",
        "            x = re.sub(r\",\", \" , \", x)\n",
        "            x = re.sub(r\"!\", \" ! \", x)\n",
        "            x = re.sub(r\"\\(\", \"\", x)\n",
        "            x = re.sub(r\"\\)\", \"\", x)\n",
        "            x = re.sub(r\"\\?\", \"\", x)\n",
        "            x = re.sub(r\"/\", \"\", x)\n",
        "            x = re.sub(r\"\\s{2,}\", \" \", x)\n",
        "            return x.lower()\n",
        "        except:\n",
        "            return ''\n",
        "\n",
        "    def lemmatizer(x):\n",
        "        return ' '.join([token.lemma_ for token in nlp(x)])\n",
        "        \n",
        "    with open('tokenizer.pickle', 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle)\n",
        "    with open('model.pickle', 'rb') as handle:\n",
        "        model = pickle.load(handle)\n",
        "\n",
        "    data = pd.DataFrame({'brand':brand,'product_full_name':product_full_name,'description':description,'details':details,'brand_category':brand_category},index=[0]) \n",
        "    df = data.copy()\n",
        "    for key in df.columns:\n",
        "        df[key] = df[key].apply(clean_text)\n",
        "        df[key] = df[key].apply(remove_stopwords)\n",
        "        df[key] = df[key].apply(lemmatizer)\n",
        "        df[key] = df[key].apply(clean_text)\n",
        "        df[key] = df[key].apply(remove_stopwords)\n",
        "    df['text'] = (df['brand'] + ' ' + df['product_full_name'] + ' ' + df['description'] + ' ' + df['brand_category'] + ' ' + df['details']).apply(str)\n",
        "    X = df['text'].values\n",
        "    X = tokenizer.texts_to_sequences(X)\n",
        "    X = pad_sequences(X, maxlen=length, padding='post')\n",
        "    results = model.predict(X)\n",
        "    results_df = pd.DataFrame()\n",
        "    results_mask = results > 0.1\n",
        "    for i in range(len(label_list)):\n",
        "        results_df[label_list[i]] = results_mask[:,i]\n",
        "        results_df[label_list[i]] = results_df[label_list[i]].apply(int)\n",
        "    results_df['sum']  = 0\n",
        "    for key in label_list:\n",
        "        results_df['sum'] = results_df['sum'] + results_df[key]\n",
        "    (results_df['sum'] == 0).sum()\n",
        "    results_df = results_df.drop(columns = ['sum'])\n",
        "    for key in label_list:\n",
        "        results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
        "\n",
        "    results_df['attribute_value'] = ''\n",
        "    for key in label_list:\n",
        "        results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
        "\n",
        "    results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
        "    data['attribute_value'] = results_df['attribute_value']\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOrLSKuvjOkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brand = \"frame\"\n",
        "product_full_name = \"les second medium noir\"\n",
        "description = \"'minimal , modern styling meet refined luxury les second caba tote craft exquisite leather , structured handbag equip adjustable high polish peg buttonhole double drop handle , center welt seam , detachable pouch , frame logo discreetly emboss'\"\n",
        "details = np.nan\n",
        "brand_category = 'accessory'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odJY4jhIjOk0",
        "colab_type": "code",
        "outputId": "d70fc419-1957-41dd-baf5-c582f0097d0b",
        "colab": {}
      },
      "source": [
        "get_fit(brand, product_full_name, description, details, brand_category)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>product_full_name</th>\n",
              "      <th>description</th>\n",
              "      <th>details</th>\n",
              "      <th>brand_category</th>\n",
              "      <th>attribute_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame</td>\n",
              "      <td>les second medium noir</td>\n",
              "      <td>'minimal , modern styling meet refined luxury ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accessory</td>\n",
              "      <td>androgynous, athleisure, boho, business, casua...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   brand       product_full_name  \\\n",
              "0  frame  les second medium noir   \n",
              "\n",
              "                                         description  details brand_category  \\\n",
              "0  'minimal , modern styling meet refined luxury ...      NaN      accessory   \n",
              "\n",
              "                                     attribute_value  \n",
              "0  androgynous, athleisure, boho, business, casua...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4a2bzrojOlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}