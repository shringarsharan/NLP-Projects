{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AishJo/Repository1/blob/master/LSTM_Glove_Category.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "buklJs6mdj5T",
    "outputId": "67c6c530-a8c2-4d0a-a8aa-dc3598a61aef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvLHOmMukGGN"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Pxdph9JB-dG"
   },
   "outputs": [],
   "source": [
    "#!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "OZMWoVO4kknG",
    "outputId": "e408decd-7fe9-4238-d9f1-111d33d5353e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential \n",
    "from keras.layers import Input, Masking\n",
    "from keras.layers import Dense, Input, Reshape\n",
    "from keras.layers import Dropout, Activation\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras.layers import Embedding\n",
    "import keras.backend as K \n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "import re \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1J88vxQgkvZY",
    "outputId": "4e368e2c-d2eb-406e-aad5-fc141e0eb270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 433 ms, sys: 82.5 ms, total: 515 ms\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reading the data\n",
    "df = pd.read_csv('/content/drive/Shared drives/DSO 560 NLP Project/data.csv')\n",
    "# creating a subset of the relevant attribute name and then dropping the column\n",
    "df = df[df['attribute_name'] == 'occasion'].drop(columns = ['attribute_name'])\n",
    "# combining similar category attribute values and removing spaces\n",
    "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'daytonight' if x == 'day night' else x)\n",
    "df['attribute_value'] = df['attribute_value'].apply(lambda x: 'nightout' if x == 'night' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "id": "vyu18_culshy",
    "outputId": "e93979d7-edbf-4eae-f403-02a2c37ad2b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01DT2D3F2NAE46MWDPFXYM57KJ</td>\n",
       "      <td>love mr mittens</td>\n",
       "      <td>cardigan wool sweater</td>\n",
       "      <td>love mr mittens ' ' the cardigan ' sweater chu...</td>\n",
       "      <td>woman clothing top</td>\n",
       "      <td>weekend</td>\n",
       "      <td>open composition 100 wool dry clean import sty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01DPGVEF7HJ2WP5J1HHS8THN5Y</td>\n",
       "      <td>frame</td>\n",
       "      <td>satin lounge tank</td>\n",
       "      <td>silky satin camisole tank , cut bias body skim...</td>\n",
       "      <td>tops blouse</td>\n",
       "      <td>weekend</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01E2KM0KW6NB1JKMZVRXR6H8G2</td>\n",
       "      <td>alo</td>\n",
       "      <td>stadium quarter zip hoodie</td>\n",
       "      <td>supersoft hoodie design elastic hem cuff perfe...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>weekend</td>\n",
       "      <td>xs 0 2 , s 4 6 , m 8 10 , l 12 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>01DPGVEF7HJ2WP5J1HHS8THN5Y</td>\n",
       "      <td>frame</td>\n",
       "      <td>satin lounge tank</td>\n",
       "      <td>silky satin camisole tank , cut bias body skim...</td>\n",
       "      <td>tops blouse</td>\n",
       "      <td>vacation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>01DTJ8G03TEWRES24T1R04W8R3</td>\n",
       "      <td>khaite</td>\n",
       "      <td>wendall crop wide leg jean</td>\n",
       "      <td>super saturated indigo , natural raw denim was...</td>\n",
       "      <td>denim</td>\n",
       "      <td>weekend</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    product_id  ...                                            details\n",
       "9   01DT2D3F2NAE46MWDPFXYM57KJ  ...  open composition 100 wool dry clean import sty...\n",
       "16  01DPGVEF7HJ2WP5J1HHS8THN5Y  ...                                                NaN\n",
       "21  01E2KM0KW6NB1JKMZVRXR6H8G2  ...                  xs 0 2 , s 4 6 , m 8 10 , l 12 14\n",
       "31  01DPGVEF7HJ2WP5J1HHS8THN5Y  ...                                                NaN\n",
       "39  01DTJ8G03TEWRES24T1R04W8R3  ...                                                NaN\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KCfa3CVn9nY"
   },
   "outputs": [],
   "source": [
    "# creating a feature combining brand, productname, description and brand category\n",
    "df['text'] = (df['brand'] + ' ' + df['product_full_name'] + ' ' + df['description'] + ' ' + df['brand_category']).apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMi2ULgelhFo"
   },
   "outputs": [],
   "source": [
    "# the predictor 'text' is assigned to 'X' and the 'attribute_value' t 'y'\n",
    "X = df['text'].values\n",
    "# one-hot-encoding the y variable\n",
    "y = pd.get_dummies(df['attribute_value'])\n",
    "label_list = y.columns\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YFmF01NwQGo"
   },
   "outputs": [],
   "source": [
    "# creating a function to create uni-grams and tokenizing data\n",
    "def encode_1gram(X, mode = 'binary'):\n",
    "    tokenizer = Tokenizer(num_words=500)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    length = max([len(s.split()) for s in df['text']])\n",
    "    X = tokenizer.texts_to_matrix(X, mode)\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    return X, length, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5oETme721eAP"
   },
   "outputs": [],
   "source": [
    "# creating a function to create bi-grams and tokenizing data\n",
    "def encode_2gram(X, mode='binary'):\n",
    "    phrases = Phrases(X, min_count=30)\n",
    "    bigrams = Phraser(phrases)\n",
    "    X = list(bigrams[X])\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=500)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    length = max([len(s.split()) for s in df['text']])\n",
    "    X = tokenizer.texts_to_matrix(X, mode)\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    return X, length, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30eS_YrlwyL9"
   },
   "outputs": [],
   "source": [
    "#Tokenizer.texts_to_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oEaE9mamM7X"
   },
   "outputs": [],
   "source": [
    "# creating tf-idf vectors from uni-gram encoding\n",
    "X1, length1, vocab_size1 = encode_1gram(X, mode = 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGFzNuUUxWmZ"
   },
   "outputs": [],
   "source": [
    "# creating tf-idf vectors from bi-gram encoding\n",
    "X2, length2, vocab_size2 = encode_2gram(X, mode = 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM7aXsN--SXZ"
   },
   "outputs": [],
   "source": [
    "#X1 = X1.reshape(-1, 155, 1)\n",
    "#X2 = X2.reshape(-1, 155, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hJpzT_ygA7Pw",
    "outputId": "e01f2942-971b-4e5e-da95-6a154a59b42e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9975, 155)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yf8Gl0NGA1HV"
   },
   "outputs": [],
   "source": [
    "# concatenating uni-gram and bi-gram\n",
    "X = np.concatenate([X1, X2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ae88zjZ9CZye"
   },
   "outputs": [],
   "source": [
    "# splitting data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "VDwRtJkSBvxp",
    "outputId": "882a6939-95a4-43ba-cb99-2b5089d16345"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# balancing the sample sets as the proportion of labels is unbalanced\n",
    "resampler = SMOTETomek(sampling_strategy = 'auto')\n",
    "X_train, y_train = resampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNTeR6ZRoxcL"
   },
   "outputs": [],
   "source": [
    "num_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xgZ_gpen5wR"
   },
   "outputs": [],
   "source": [
    "# defining LSTM model with sigmoid activation functions for prediction\n",
    "def define_model():\n",
    "    inputs = Input(shape=(length1+length2,))\n",
    "    #x1 = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(inputs1)\n",
    "    embedding = Embedding(input_dim=vocab_size1, output_dim=100)(inputs)\n",
    "\n",
    "    #inputs2 = Input(shape=(length2,))\n",
    "    #x2 = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(inputs2)\n",
    "    #dense2 = Dense(100, activation='relu')(inputs2)\n",
    "    #embedding2 = Embedding(input_dim=vocab_size2, output_dim=100)(inputs2)\n",
    "\n",
    "    #merged = concatenate([inputs1, inputs1])\n",
    "    x = LSTM(16, return_sequences=True, dropout=0.2, recurrent_dropout=0.15)(embedding)\n",
    "\n",
    "    #x = Dense(100, activation = 'relu')(inputs)\n",
    "\n",
    "\n",
    "    x = Conv1D(filters=num_classes, kernel_size=1, padding='valid')(x)\n",
    "    x = Conv1D(filters=num_classes, kernel_size=length1+length2, padding='valid')(x)\n",
    "    x = Reshape((num_classes,))(x)\n",
    "    #x = Dense(num_classes)(x)\n",
    "    out = Activation('sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs = [inputs], outputs = out)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "colab_type": "code",
    "id": "WtVkDeU4pOFw",
    "outputId": "37b64020-7d76-4558-f96d-ac472db337b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 310)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 310, 100)          609900    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 310, 16)           7488      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 310, 7)            119       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 7)              15197     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 632,704\n",
      "Trainable params: 632,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "wfeN4H1XpRvM",
    "outputId": "7d4e04e7-2f35-49a8-83de-437ac0c9c673"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17098 samples, validate on 4275 samples\n",
      "Epoch 1/10\n",
      "17098/17098 [==============================] - 37s 2ms/step - loss: 0.4702 - accuracy: 0.8303 - val_loss: 0.6500 - val_accuracy: 0.8571\n",
      "Epoch 2/10\n",
      "17098/17098 [==============================] - 32s 2ms/step - loss: 0.3902 - accuracy: 0.8571 - val_loss: 0.7665 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "17098/17098 [==============================] - 32s 2ms/step - loss: 0.3891 - accuracy: 0.8571 - val_loss: 0.7366 - val_accuracy: 0.8571\n",
      "Epoch 4/10\n",
      "17098/17098 [==============================] - 31s 2ms/step - loss: 0.3891 - accuracy: 0.8571 - val_loss: 0.7351 - val_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "17098/17098 [==============================] - 31s 2ms/step - loss: 0.3886 - accuracy: 0.8571 - val_loss: 0.7228 - val_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "17098/17098 [==============================] - 31s 2ms/step - loss: 0.3876 - accuracy: 0.8571 - val_loss: 0.7340 - val_accuracy: 0.8571\n",
      "Epoch 7/10\n",
      "17098/17098 [==============================] - 32s 2ms/step - loss: 0.3847 - accuracy: 0.8571 - val_loss: 0.7340 - val_accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "17098/17098 [==============================] - 32s 2ms/step - loss: 0.3778 - accuracy: 0.8569 - val_loss: 0.7102 - val_accuracy: 0.8571\n",
      "Epoch 9/10\n",
      "17098/17098 [==============================] - 33s 2ms/step - loss: 0.3703 - accuracy: 0.8569 - val_loss: 0.7000 - val_accuracy: 0.8558\n",
      "Epoch 10/10\n",
      "17098/17098 [==============================] - 31s 2ms/step - loss: 0.3645 - accuracy: 0.8573 - val_loss: 0.6769 - val_accuracy: 0.8551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd94099dc50>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting data onto model\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RH0rgY1WChE4",
    "outputId": "23dfe11a-0304-46ae-d8fd-10d79cbf55e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998/998 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3844574683295462, 0.8548527359962463]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58YGb44Ln1sL"
   },
   "outputs": [],
   "source": [
    "# probability of predicting each class for various records\n",
    "results = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6FgcHherHja"
   },
   "outputs": [],
   "source": [
    "#Creating a DataFrame for the results\n",
    "results_df = pd.DataFrame()\n",
    "results_mask = results > 0.1\n",
    "for i in range(len(label_list)):\n",
    "    results_df[label_list[i]] = results_mask[:,i]\n",
    "    results_df[label_list[i]] = results_df[label_list[i]].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YpNDlwRQsFj5",
    "outputId": "f1e52179-d926-4b40-c124-1b80654175f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['sum']  = 0\n",
    "for key in label_list:\n",
    "    results_df['sum'] = results_df['sum'] + results_df[key]\n",
    "(results_df['sum'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "5WsQqrmxprsc",
    "outputId": "8e38ddc7-ce3b-4346-bf0f-0db3ac44d18b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coldweather</th>\n",
       "      <th>daytonight</th>\n",
       "      <th>nightout</th>\n",
       "      <th>vacation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>work</th>\n",
       "      <th>workout</th>\n",
       "      <th>attribute_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coldweather</td>\n",
       "      <td>daytonight</td>\n",
       "      <td>nightout</td>\n",
       "      <td>vacation</td>\n",
       "      <td>weekend</td>\n",
       "      <td>work</td>\n",
       "      <td></td>\n",
       "      <td>coldweather, daytonight, nightout, vacation, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>daytonight</td>\n",
       "      <td>nightout</td>\n",
       "      <td>vacation</td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>daytonight, nightout, vacation, weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coldweather</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td>workout</td>\n",
       "      <td>coldweather, weekend, workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>daytonight</td>\n",
       "      <td>nightout</td>\n",
       "      <td>vacation</td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>daytonight, nightout, vacation, weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>daytonight</td>\n",
       "      <td>nightout</td>\n",
       "      <td></td>\n",
       "      <td>weekend</td>\n",
       "      <td>work</td>\n",
       "      <td></td>\n",
       "      <td>daytonight, nightout, weekend, work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coldweather  ...                                    attribute_value\n",
       "0  coldweather  ...  coldweather, daytonight, nightout, vacation, w...\n",
       "1               ...            daytonight, nightout, vacation, weekend\n",
       "2  coldweather  ...                      coldweather, weekend, workout\n",
       "3               ...            daytonight, nightout, vacation, weekend\n",
       "4               ...                daytonight, nightout, weekend, work\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df.drop(columns = ['sum'])\n",
    "for key in label_list:\n",
    "    results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
    "\n",
    "results_df['attribute_value'] = ''\n",
    "for key in label_list:\n",
    "    results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
    "\n",
    "results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "BmfNQQbrqhhc",
    "outputId": "62c96e91-94fe-40ee-d3e2-d9f66871fb37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coldweather, daytonight, nightout, vacation, weekend          3857\n",
       "daytonight, nightout, weekend, work                           1299\n",
       "daytonight, nightout, vacation, weekend                        961\n",
       "daytonight, nightout, weekend                                  698\n",
       "daytonight, nightout, vacation, weekend, work                  695\n",
       "coldweather, daytonight, nightout, vacation, weekend, work     611\n",
       "coldweather, daytonight, nightout, weekend, work               397\n",
       "daytonight, weekend, work                                      362\n",
       "daytonight, vacation, weekend                                  275\n",
       "daytonight, vacation, weekend, work                            225\n",
       "daytonight, weekend                                            135\n",
       "coldweather, daytonight, nightout, weekend                     115\n",
       "coldweather, daytonight, weekend, work                         101\n",
       "coldweather, daytonight, weekend                                58\n",
       "coldweather, daytonight, vacation, weekend                      34\n",
       "daytonight, weekend, workout                                    32\n",
       "daytonight, weekend, work, workout                              22\n",
       "coldweather, weekend                                            18\n",
       "coldweather, daytonight, nightout, work                         17\n",
       "coldweather, daytonight, weekend, work, workout                 17\n",
       "coldweather, daytonight, weekend, workout                       14\n",
       "daytonight, nightout, weekend, workout                          14\n",
       "nightout, weekend, workout                                       7\n",
       "coldweather, daytonight, vacation, weekend, work                 5\n",
       "coldweather, weekend, workout                                    2\n",
       "coldweather, daytonight, nightout, weekend, workout              2\n",
       "coldweather, weekend, work, workout                              2\n",
       "Name: attribute_value, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['attribute_value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8ZYTciwp-Oc"
   },
   "outputs": [],
   "source": [
    "# the predictor 'text' is assigned to 'X' and the 'attribute_value' t 'y'\n",
    "X = df['text'].values\n",
    "# one-hot-encoding the y variable\n",
    "y = pd.get_dummies(df['attribute_value'])\n",
    "label_list = y.columns\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZ9stl_mp-Oe"
   },
   "outputs": [],
   "source": [
    "# tokenizing the data and integer encoding it\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIbQGJnip-Og"
   },
   "outputs": [],
   "source": [
    "# running the tokenizer function on features\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IMFmGLi6sUH"
   },
   "outputs": [],
   "source": [
    "# getting vocab size and length for input\n",
    "length = max([len(s.split()) for s in df['text']])\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHn0BxkM6zbH"
   },
   "outputs": [],
   "source": [
    "# padding the data to make it same size (max size)\n",
    "X = pad_sequences(X, maxlen=length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_CDDlidp-Om"
   },
   "outputs": [],
   "source": [
    "# splitting training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "YAHcze6Up-Os",
    "outputId": "649f0681-f718-403f-a9fc-43b9642007c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# balancing the dataset to account for disproportionate of labels\n",
    "resampler = SMOTETomek(sampling_strategy = 'auto')\n",
    "X_train, y_train = resampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSujBXCjp-Ov"
   },
   "outputs": [],
   "source": [
    "num_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8F-6edne7CKl",
    "outputId": "c9a1e187-89ca-4116-e556-5f94983980c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# using glove vector to create function that makes word emebeddings\n",
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('/content/drive/Shared drives/DSO 560 NLP Project/glove.6B.100d.txt') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cm2saCqq7B6t"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcWVkLPD7Bq6"
   },
   "outputs": [],
   "source": [
    "# creating an LSTM model\n",
    "def define_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=length, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.15, activation = 'relu'))\n",
    "    model.add(LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.15, activation = 'relu'))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwR86N_D8RPY"
   },
   "source": [
    "def define_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=length, trainable=False))\n",
    "    #model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.15, activation = 'relu')\n",
    "    LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.15, activation = 'relu')\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "j1aDd4wvp-O5",
    "outputId": "fd6397d5-daba-4b8d-b703-f31037618ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 155, 100)          610000    \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 155, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 155, 64)           42240     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 686,423\n",
      "Trainable params: 76,423\n",
      "Non-trainable params: 610,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "SFLAht0pp-O7",
    "outputId": "7cbebf4e-8979-47a3-bd62-0931222eb305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16927 samples, validate on 4232 samples\n",
      "Epoch 1/10\n",
      "16927/16927 [==============================] - 43s 3ms/step - loss: 0.5418 - accuracy: 0.7870 - val_loss: 0.5341 - val_accuracy: 0.8571\n",
      "Epoch 2/10\n",
      "16927/16927 [==============================] - 42s 3ms/step - loss: 0.4513 - accuracy: 0.8570 - val_loss: 0.5557 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "16927/16927 [==============================] - 43s 3ms/step - loss: 0.4201 - accuracy: 0.8571 - val_loss: 0.6073 - val_accuracy: 0.8571\n",
      "Epoch 4/10\n",
      "16927/16927 [==============================] - 43s 3ms/step - loss: 0.3952 - accuracy: 0.8571 - val_loss: 0.6510 - val_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "16927/16927 [==============================] - 43s 3ms/step - loss: 0.3880 - accuracy: 0.8571 - val_loss: 0.7040 - val_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "16927/16927 [==============================] - 43s 3ms/step - loss: 0.3821 - accuracy: 0.8570 - val_loss: 0.7463 - val_accuracy: 0.8571\n",
      "Epoch 7/10\n",
      "16927/16927 [==============================] - 43s 3ms/step - loss: 0.3761 - accuracy: 0.8570 - val_loss: 0.7540 - val_accuracy: 0.8569\n",
      "Epoch 8/10\n",
      "16927/16927 [==============================] - 44s 3ms/step - loss: 0.3708 - accuracy: 0.8566 - val_loss: 0.7747 - val_accuracy: 0.8550\n",
      "Epoch 9/10\n",
      "16927/16927 [==============================] - 44s 3ms/step - loss: 0.3677 - accuracy: 0.8567 - val_loss: 0.7593 - val_accuracy: 0.8444\n",
      "Epoch 10/10\n",
      "16927/16927 [==============================] - 43s 3ms/step - loss: 0.3645 - accuracy: 0.8569 - val_loss: 0.7556 - val_accuracy: 0.8453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd9306f9e80>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model on training data\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "smktW8XFp-O9",
    "outputId": "1d9075e0-f248-4edd-9ed3-7d8565b72144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998/998 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3765581901780589, 0.8569998145103455]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ythmDKKlpjsc"
   },
   "outputs": [],
   "source": [
    "# making predictions\n",
    "results = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xjn1GCho_snJ"
   },
   "outputs": [],
   "source": [
    "# defining a threshold for prediction\n",
    "results_df = pd.DataFrame()\n",
    "results_mask = results > 0.2\n",
    "for i in range(len(label_list)):\n",
    "    results_df[label_list[i]] = results_mask[:,i]\n",
    "    results_df[label_list[i]] = results_df[label_list[i]].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "alvpuQgQp-PF",
    "outputId": "b100b557-ed6d-4070-89b3-ee416eea57d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['sum']  = 0\n",
    "for key in label_list:\n",
    "    results_df['sum'] = results_df['sum'] + results_df[key]\n",
    "(results_df['sum'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "0j6oSLCCp-PJ",
    "outputId": "1d61fd2b-64e1-4fa4-8f53-5fbf385a9af2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coldweather</th>\n",
       "      <th>daytonight</th>\n",
       "      <th>nightout</th>\n",
       "      <th>vacation</th>\n",
       "      <th>weekend</th>\n",
       "      <th>work</th>\n",
       "      <th>workout</th>\n",
       "      <th>attribute_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>daytonight</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>daytonight, weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coldweather</td>\n",
       "      <td></td>\n",
       "      <td>nightout</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>coldweather, nightout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coldweather</td>\n",
       "      <td>daytonight</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>coldweather, daytonight, weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coldweather</td>\n",
       "      <td></td>\n",
       "      <td>nightout</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>coldweather, nightout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>daytonight</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>weekend</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>daytonight, weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coldweather  daytonight  ... workout                   attribute_value\n",
       "0               daytonight  ...                       daytonight, weekend\n",
       "1  coldweather              ...                     coldweather, nightout\n",
       "2  coldweather  daytonight  ...          coldweather, daytonight, weekend\n",
       "3  coldweather              ...                     coldweather, nightout\n",
       "4               daytonight  ...                       daytonight, weekend\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df.drop(columns = ['sum'])\n",
    "for key in label_list:\n",
    "    results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
    "\n",
    "results_df['attribute_value'] = ''\n",
    "for key in label_list:\n",
    "    results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
    "\n",
    "results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "kBsLjXEzyvys",
    "outputId": "e0baf3e1-4935-4b76-9749-84d79eee2afe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "daytonight, weekend                        4988\n",
       "coldweather, vacation, weekend             1372\n",
       "daytonight, nightout, weekend              1208\n",
       "coldweather, daytonight, weekend            832\n",
       "nightout                                    238\n",
       "nightout, vacation                          231\n",
       "coldweather, weekend                        189\n",
       "daytonight, nightout                        170\n",
       "coldweather                                 167\n",
       "daytonight, nightout, vacation              155\n",
       "coldweather, nightout                       139\n",
       "coldweather, nightout, vacation             118\n",
       "                                             50\n",
       "daytonight, nightout, vacation, weekend      39\n",
       "weekend                                      33\n",
       "coldweather, vacation                        18\n",
       "nightout, weekend                            11\n",
       "vacation                                      8\n",
       "daytonight, vacation                          6\n",
       "daytonight                                    3\n",
       "Name: attribute_value, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['attribute_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8G0Q1SjfeQv"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('model.pickle', 'wb') as handle:\n",
    "    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZFAGD_chS6z"
   },
   "outputs": [],
   "source": [
    "def get_occasion(brand, product_full_name, description, details, brand_category):\n",
    "    def clean_text(x):\n",
    "        try:\n",
    "            x = re.sub(r'<.*?>', '',x)\n",
    "            x = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", x)\n",
    "            x = re.sub(r\"\\'s\", \" \\'s\", x)\n",
    "            x = re.sub(r\"\\'ve\", \" \\'ve\", x)\n",
    "            x = re.sub(r\"n\\'t\", \" n\\'t\", x)\n",
    "            x = re.sub(r\"\\'re\", \" \\'re\", x)\n",
    "            x = re.sub(r\"\\'d\", \" \\'d\", x)\n",
    "            x = re.sub(r\"\\'ll\", \" \\'ll\", x)\n",
    "            x = re.sub(r\",\", \" , \", x)\n",
    "            x = re.sub(r\"!\", \" ! \", x)\n",
    "            x = re.sub(r\"\\(\", \"\", x)\n",
    "            x = re.sub(r\"\\)\", \"\", x)\n",
    "            x = re.sub(r\"\\?\", \"\", x)\n",
    "            x = re.sub(r\"/\", \"\", x)\n",
    "            x = re.sub(r\"\\s{2,}\", \" \", x)\n",
    "            return x.lower()\n",
    "        except:\n",
    "            return ''\n",
    "\n",
    "    def lemmatizer(x):\n",
    "        return ' '.join([token.lemma_ for token in nlp(x)])\n",
    "        \n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    with open('model.pickle', 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "\n",
    "    data = pd.DataFrame({'brand':brand,'product_full_name':product_full_name,'description':description,'details':details,'brand_category':brand_category},index=[0]) \n",
    "    df = data.copy()\n",
    "    for key in df.columns:\n",
    "        df[key] = df[key].apply(clean_text)\n",
    "        df[key] = df[key].apply(remove_stopwords)\n",
    "        df[key] = df[key].apply(lemmatizer)\n",
    "        df[key] = df[key].apply(clean_text)\n",
    "        df[key] = df[key].apply(remove_stopwords)\n",
    "    df['text'] = (df['brand'] + ' ' + df['product_full_name'] + ' ' + df['description'] + ' ' + df['brand_category'] + ' ' + df['details']).apply(str)\n",
    "    X = df['text'].values\n",
    "    X = tokenizer.texts_to_sequences(X)\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    results = model.predict(X)\n",
    "    results_df = pd.DataFrame()\n",
    "    results_mask = results > 0.1\n",
    "    for i in range(len(label_list)):\n",
    "        results_df[label_list[i]] = results_mask[:,i]\n",
    "        results_df[label_list[i]] = results_df[label_list[i]].apply(int)\n",
    "    results_df['sum']  = 0\n",
    "    for key in label_list:\n",
    "        results_df['sum'] = results_df['sum'] + results_df[key]\n",
    "    (results_df['sum'] == 0).sum()\n",
    "    results_df = results_df.drop(columns = ['sum'])\n",
    "    for key in label_list:\n",
    "        results_df[key] = results_df[key].apply(lambda x: key if x == 1 else '')\n",
    "\n",
    "    results_df['attribute_value'] = ''\n",
    "    for key in label_list:\n",
    "        results_df['attribute_value'] = results_df['attribute_value'] + ' ' + results_df[key]\n",
    "\n",
    "    results_df['attribute_value'] = results_df['attribute_value'].apply(lambda x: ', '.join(x.split()))\n",
    "    data['attribute_value'] = results_df['attribute_value']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHysGjOuhlea"
   },
   "outputs": [],
   "source": [
    "brand = \"frame\"\n",
    "product_full_name = \"les second medium noir\"\n",
    "description = \"'minimal , modern styling meet refined luxury les second caba tote craft exquisite leather , structured handbag equip adjustable high polish peg buttonhole double drop handle , center welt seam , detachable pouch , frame logo discreetly emboss'\"\n",
    "details = np.nan\n",
    "brand_category = 'accessory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "Wq_DOyMbhrm4",
    "outputId": "a36d4d22-53c8-4d73-cff4-d04ddd6f7f40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>details</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>attribute_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame</td>\n",
       "      <td>les second medium noir</td>\n",
       "      <td>'minimal , modern styling meet refined luxury ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accessory</td>\n",
       "      <td>daytonight, nightout, vacation, weekend, work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand  ...                                attribute_value\n",
       "0  frame  ...  daytonight, nightout, vacation, weekend, work\n",
       "\n",
       "[1 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_occasion(brand, product_full_name, description, details, brand_category)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Occasion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
